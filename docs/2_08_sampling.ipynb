{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f29b522c2c2aa91",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26028e22e4fc5c22",
   "metadata": {},
   "source": [
    "A sampler provides an unlimited series of samples from a joint distribution over one or more random variables. Specifically, a sampler implements the abstract base class, `Sampler` in the `ck.sampling` package.\n",
    "\n",
    "All samplers have an `rvs` and `condition` property.\n",
    "\n",
    "The `rvs` property records what random variables are being sampled. They will all be from the same PGM. The order of the random variables provided by `rvs` is important.\n",
    "\n",
    "The `condition` property records the conditions placed on the sampler at construction time.\n",
    "\n",
    "A Sampler will either iterate over `Instance` objects (each instance having states co-indexed\n",
    "with its `rvs`) or will iterate over integers (each integer being a single state index). Whether a Sampler iterates\n",
    "over `Instance` objects or integers is determined by the implementation.\n",
    "\n",
    "If a sampler iterates over integers, then the length of its `rvs` is 1.\n",
    "\n",
    "To explain samplers, we will use an example PGM..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8acbd390c0f7662e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:02:05.734185Z",
     "start_time": "2025-05-14T02:02:05.631433Z"
    },
    "execution": {
     "iopub.execute_input": "2025-08-07T23:40:19.902332Z",
     "iopub.status.busy": "2025-08-07T23:40:19.901332Z",
     "iopub.status.idle": "2025-08-07T23:40:19.940351Z",
     "shell.execute_reply": "2025-08-07T23:40:19.940351Z"
    }
   },
   "outputs": [],
   "source": [
    "from ck.example import Asia\n",
    "from ck.pgm import RVMap\n",
    "\n",
    "pgm = Asia()  # An example PGM to demonstrate samplers\n",
    "\n",
    "rvs = RVMap(pgm)  # Provide easy access to the PGM random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9300de002eb07c9",
   "metadata": {},
   "source": [
    "## Forward Sampling\n",
    "\n",
    "CK provides an implementation of the Forward Sampling algorithm, `ForwardSampler` in the `ck.sampling.forward_sampler` package. A forward sampler can be constructed directly from a PGM, so long as the PGM represents a Bayesian network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd7ca04764da3c9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:02:05.755089Z",
     "start_time": "2025-05-14T02:02:05.737193Z"
    },
    "execution": {
     "iopub.execute_input": "2025-08-07T23:40:19.942361Z",
     "iopub.status.busy": "2025-08-07T23:40:19.942361Z",
     "iopub.status.idle": "2025-08-07T23:40:19.958979Z",
     "shell.execute_reply": "2025-08-07T23:40:19.958979Z"
    }
   },
   "outputs": [],
   "source": [
    "from ck.sampling.forward_sampler import ForwardSampler\n",
    "\n",
    "forward_sampler = ForwardSampler(pgm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982081875bdcfa83",
   "metadata": {},
   "source": [
    "A sampler provides an infinite iterator over instances.\n",
    "\n",
    "In this example we limit ourselves to 8 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad07e154762d4c55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:02:05.923088Z",
     "start_time": "2025-05-14T02:02:05.919527Z"
    },
    "execution": {
     "iopub.execute_input": "2025-08-07T23:40:19.960983Z",
     "iopub.status.busy": "2025-08-07T23:40:19.959982Z",
     "iopub.status.idle": "2025-08-07T23:40:19.963921Z",
     "shell.execute_reply": "2025-08-07T23:40:19.963921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asia tub smoke lung bronc either xray dysp\n",
      "1 [1, 1, 0, 1, 0, 1, 1, 0]\n",
      "2 [1, 1, 0, 1, 0, 1, 1, 0]\n",
      "3 [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "4 [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "5 [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "6 [1, 1, 0, 1, 1, 1, 1, 1]\n",
      "7 [1, 1, 0, 1, 0, 1, 1, 1]\n",
      "8 [1, 1, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(*forward_sampler.rvs)  # Show the random variables\n",
    "\n",
    "# Draw some samples\n",
    "for i, inst in enumerate(forward_sampler, start=1):\n",
    "    print(i, inst)\n",
    "    if i == 8:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8727d55f8e9ad777",
   "metadata": {},
   "source": [
    "A simple way to take a limited number of samples is to use `take`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ea8adef4b2f9b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:02:05.939861Z",
     "start_time": "2025-05-14T02:02:05.929341Z"
    },
    "execution": {
     "iopub.execute_input": "2025-08-07T23:40:19.965925Z",
     "iopub.status.busy": "2025-08-07T23:40:19.964925Z",
     "iopub.status.idle": "2025-08-07T23:40:19.968293Z",
     "shell.execute_reply": "2025-08-07T23:40:19.968293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 0]\n",
      "[1, 1, 0, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 0, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 0, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "for inst in forward_sampler.take(8):\n",
    "    print(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2043e880f08057b0",
   "metadata": {},
   "source": [
    "Most samplers can also be constructed to sample a PGM with some random variables conditioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5085aec786a08158",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:02:06.334259Z",
     "start_time": "2025-05-14T02:02:05.944652Z"
    },
    "execution": {
     "iopub.execute_input": "2025-08-07T23:40:19.969296Z",
     "iopub.status.busy": "2025-08-07T23:40:19.969296Z",
     "iopub.status.idle": "2025-08-07T23:40:20.269352Z",
     "shell.execute_reply": "2025-08-07T23:40:20.269352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 0, 0, 1, 0]\n",
      "[1, 1, 1, 0, 1, 0, 1, 1]\n",
      "[1, 1, 1, 0, 0, 0, 1, 0]\n",
      "[1, 1, 1, 0, 1, 0, 1, 0]\n",
      "[1, 1, 1, 0, 0, 0, 1, 0]\n",
      "[1, 1, 1, 0, 1, 0, 1, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 1, 0, 1, 0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "# Construct a condition where smoke = no, lung = yes, xray = no.\n",
    "condition = (rvs.smoke('no'), rvs.lung('yes'), rvs.xray('no'))\n",
    "\n",
    "forward_sampler = ForwardSampler(pgm, condition=condition)\n",
    "\n",
    "for inst in forward_sampler.take(8):\n",
    "    print(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1638411659bdb3",
   "metadata": {},
   "source": [
    "A forward sample is very efficient for sampling Bayesian networks, without conditioning. However, conditioning can make a forward sampler slow, especially for low-probability conditions, as the forward sample needs to use rejection sampling to implement the condition.\n",
    "\n",
    "The timing difference may be apparent in the two examples above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218c103df735fc3",
   "metadata": {},
   "source": [
    "## Uniform Sampler\n",
    "\n",
    "Another sampler that can be created directly from a PGM is a `UniformSampler` in package `ck.sampling.uniform_sampler`. It only requires a list of random variables as it will sample them assuming a uniform distribution.\n",
    "\n",
    "A `UniformSampler` is very computationally efficient (as it does not require any analysis of the probability distribution of a PGM). The main purpose of this sampler is to provide a trivial baseline (in terms of speed and accuracy) when comparing sampling algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d81a52992155390e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:02:06.343898Z",
     "start_time": "2025-05-14T02:02:06.340019Z"
    },
    "execution": {
     "iopub.execute_input": "2025-08-07T23:40:20.271356Z",
     "iopub.status.busy": "2025-08-07T23:40:20.271356Z",
     "iopub.status.idle": "2025-08-07T23:40:20.275048Z",
     "shell.execute_reply": "2025-08-07T23:40:20.275048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asia tub smoke lung bronc either xray dysp\n",
      "[1, 1, 0, 0, 1, 0, 0, 1]\n",
      "[1, 0, 1, 1, 0, 1, 1, 0]\n",
      "[0, 1, 0, 1, 0, 1, 1, 1]\n",
      "[1, 1, 1, 0, 1, 0, 0, 0]\n",
      "[1, 1, 0, 0, 1, 1, 0, 1]\n",
      "[0, 1, 1, 1, 0, 1, 1, 0]\n",
      "[0, 0, 0, 0, 1, 0, 1, 1]\n",
      "[0, 0, 1, 0, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "from ck.sampling.uniform_sampler import UniformSampler\n",
    "\n",
    "uniform_sampler = UniformSampler(pgm.rvs)\n",
    "\n",
    "print(*uniform_sampler.rvs)\n",
    "\n",
    "for inst in uniform_sampler.take(8):\n",
    "    print(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3c81baa7ec9e3a",
   "metadata": {},
   "source": [
    "## Gibbs Sampler\n",
    "\n",
    "Gibbs sampling is a common approach to sampling a probability distribution. There are many explanations available for this approach (see https://en.wikipedia.org/wiki/Gibbs_sampling).\n",
    "\n",
    "Gibbs sampling is a type of \"dependant\" sampling, which is where a Markov chain is used to generate samples - nearby samples in the sequence are correlated. It may not be suitable if independent samples are desired.\n",
    "\n",
    "To perform Gibbs sampling in CK, a PGM must first be compiled to a `WMCProgram`. Here is an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e2df6ae188f28cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:02:06.431374Z",
     "start_time": "2025-05-14T02:02:06.348365Z"
    },
    "execution": {
     "iopub.execute_input": "2025-08-07T23:40:20.277053Z",
     "iopub.status.busy": "2025-08-07T23:40:20.276052Z",
     "iopub.status.idle": "2025-08-07T23:40:20.347980Z",
     "shell.execute_reply": "2025-08-07T23:40:20.347980Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 1, 0, 0, 1]\n",
      "[0, 0, 1, 1, 1, 0, 0, 0]\n",
      "[1, 0, 1, 1, 0, 0, 0, 0]\n",
      "[1, 0, 0, 1, 1, 0, 0, 0]\n",
      "[1, 0, 1, 1, 1, 0, 0, 1]\n",
      "[1, 0, 0, 1, 0, 0, 0, 0]\n",
      "[1, 0, 0, 1, 1, 0, 0, 1]\n",
      "[1, 0, 0, 1, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "from ck.pgm_compiler import DEFAULT_PGM_COMPILER\n",
    "from ck.pgm_circuit.wmc_program import WMCProgram\n",
    "\n",
    "wmc = WMCProgram(DEFAULT_PGM_COMPILER(pgm))\n",
    "\n",
    "gibbs_sampler = wmc.sample_gibbs()\n",
    "\n",
    "for inst in gibbs_sampler.take(8):\n",
    "    print(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31afd96abf4a9d68",
   "metadata": {},
   "source": [
    "## Metropolis–Hastings Sampler\n",
    "\n",
    "Metropolis–Hastings sampling is another common approach to sampling a probability distribution (see https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm).\n",
    "\n",
    "Metropolis–Hastings sampling is also a type of \"dependant\" sampling - nearby samples in the sequence are correlated.\n",
    "\n",
    "CK creates a Metropolis–Hastings sampler from a `WMCProgram`. Here is an example using the `WMCProgram` created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eafb0145053b7ca9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:02:06.440442Z",
     "start_time": "2025-05-14T02:02:06.436146Z"
    },
    "execution": {
     "iopub.execute_input": "2025-08-07T23:40:20.349986Z",
     "iopub.status.busy": "2025-08-07T23:40:20.348985Z",
     "iopub.status.idle": "2025-08-07T23:40:20.353194Z",
     "shell.execute_reply": "2025-08-07T23:40:20.353194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 0, 1, 0, 0, 0]\n",
      "[1, 1, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 0, 0, 0, 0, 0, 0]\n",
      "[1, 1, 0, 0, 1, 0, 0, 0]\n",
      "[1, 1, 0, 0, 1, 0, 0, 0]\n",
      "[1, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "metropolis_sampler = wmc.sample_metropolis()\n",
    "\n",
    "for inst in metropolis_sampler.take(8):\n",
    "    print(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deba5e7a3399484",
   "metadata": {},
   "source": [
    "## Rejection Sampler\n",
    "\n",
    "Rejection sampling is a technique for converting samples from a source distribution into a samples from a target distribution (see https://en.wikipedia.org/wiki/Rejection_sampling). It does this by randomly discarding samples from the source distribution to match the target distribution.\n",
    "\n",
    "In CK the source distribution is from an independent, uniform sampler. In this case, rejection sampling is a type of \"independent sampling\" - nearby samples in the sequence are _not_ correlated.\n",
    "\n",
    "CK creates a rejection sampler from a `WMCProgram`. Here is an example using the `WMCProgram` created above.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "377b1dfe1a0ed9c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:02:06.465885Z",
     "start_time": "2025-05-14T02:02:06.453298Z"
    },
    "execution": {
     "iopub.execute_input": "2025-08-07T23:40:20.355199Z",
     "iopub.status.busy": "2025-08-07T23:40:20.354199Z",
     "iopub.status.idle": "2025-08-07T23:40:20.369294Z",
     "shell.execute_reply": "2025-08-07T23:40:20.369294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 1, 0, 1, 1, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 0, 1, 0, 1, 1, 0]\n",
      "[1, 1, 0, 1, 0, 1, 1, 0]\n",
      "[1, 1, 0, 1, 0, 1, 1, 0]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 0, 1, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "rejection_sampler = wmc.sample_rejection()\n",
    "\n",
    "for inst in rejection_sampler.take(8):\n",
    "    print(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1811bf7080ce1f4",
   "metadata": {},
   "source": [
    "## WMC Direct Sampler\n",
    "\n",
    "CK provides two custom sampling methods that exploit efficiencies gained from compiling PGMs and circuits. They are called \"WMC Direct\" sampler and \"Marginals Direct\" sampler. They are both based on \"inverse transform sampling\" which is a type of \"independent\" sampling - nearby samples in the sequence are _not_ correlated (see https://en.wikipedia.org/wiki/Inverse_transform_sampling).\n",
    "\n",
    "The algorithms are described and evaluated in the publication: Suresh, S., Drake, B. (2025). Sampling of Large Probabilistic Graphical Models Using Arithmetic Circuits. AI 2024: Advances in Artificial Intelligence. AI 2024. Lecture Notes in Computer Science, vol 15443. https://doi.org/10.1007/978-981-96-0351-0_13.\n",
    "\n",
    "So long as a PGM can be efficiently compiled to an arithmetic circuit, then a WMC Direct sampler is a computationally efficient independent sampler, even for complex probability distributions and when the probability distribution is conditioned after compilation.\n",
    "\n",
    "Here is an example of the WMC Direct sampler using the `WMCProgram` created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29fd7fc83eed9f63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:02:06.477441Z",
     "start_time": "2025-05-14T02:02:06.473849Z"
    },
    "execution": {
     "iopub.execute_input": "2025-08-07T23:40:20.371299Z",
     "iopub.status.busy": "2025-08-07T23:40:20.371299Z",
     "iopub.status.idle": "2025-08-07T23:40:20.374515Z",
     "shell.execute_reply": "2025-08-07T23:40:20.374515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 0]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0]\n",
      "[1, 1, 1, 1, 0, 1, 1, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 0, 1, 0, 1, 1, 0]\n",
      "[1, 1, 0, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "wmc_direct_sampler = wmc.sample_direct()\n",
    "\n",
    "for inst in wmc_direct_sampler.take(8):\n",
    "    print(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63ba8713c8a2e23",
   "metadata": {},
   "source": [
    "## Marginals Direct Sampler\n",
    "\n",
    "A variation on the \"WMC Direct\" sampler is the \"Marginals Direct\" sampler.\n",
    "\n",
    "The Marginals Direct sampler is based on \"inverse transform sampling\" but calculates an inverse cumulative probability function differently to WMC Direct. Specifically, is uses the so-called differential approach to computing marginal distributions. This approach to marginal distributions is described in the publication: Adnan Darwiche (2003). A differential approach to inference in Bayesian networks. J. ACM 50, 3 (May 2003), 280–305. https://doi.org/10.1145/765568.765570.\n",
    "\n",
    "The Marginals Direct algorithm is described and evaluated in the publication: Suresh, S., Drake, B. (2025). Sampling of Large Probabilistic Graphical Models Using Arithmetic Circuits. AI 2024: Advances in Artificial Intelligence. AI 2024. Lecture Notes in Computer Science, vol 15443. https://doi.org/10.1007/978-981-96-0351-0_13.\n",
    "\n",
    "So long as a PGM can be efficiently compiled to an arithmetic circuit, then a Marginals Direct sampler is a computationally efficient independent sampler, even for complex probability distributions and when the probability distribution is conditioned after compilation.\n",
    "\n",
    "Here is an example of the Marginals Direct sampler using the `WMCProgram` created above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4ebdc6e4f17f94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-14T02:02:06.510208Z",
     "start_time": "2025-05-14T02:02:06.494315Z"
    },
    "execution": {
     "iopub.execute_input": "2025-08-07T23:40:20.376520Z",
     "iopub.status.busy": "2025-08-07T23:40:20.375519Z",
     "iopub.status.idle": "2025-08-07T23:40:20.382681Z",
     "shell.execute_reply": "2025-08-07T23:40:20.382681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 1, 0, 1, 1, 0]\n",
      "[1, 1, 0, 1, 0, 1, 1, 0]\n",
      "[1, 1, 1, 1, 0, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 0, 1, 1, 1, 1, 0]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[1, 1, 0, 0, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from ck.pgm_circuit.marginals_program import MarginalsProgram\n",
    "\n",
    "marginals = MarginalsProgram(DEFAULT_PGM_COMPILER(pgm))\n",
    "\n",
    "marginals_direct = marginals.sample_direct()\n",
    "\n",
    "for inst in marginals_direct.take(8):\n",
    "    print(inst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f92f8e4874a360",
   "metadata": {},
   "source": [
    "## Options When Creating Samplers\n",
    "\n",
    "When creating a Direct sampler (from `WMCProgram` or `MarginaslProgram`) several options are available to customize the sampler. Here is the function signature.\n",
    "\n",
    "```\n",
    "sample_direct(\n",
    "        rvs: Optional[RandomVariable | Sequence[RandomVariable]] = None,\n",
    "        *,\n",
    "        condition: Condition = (),\n",
    "        rand: Random = random,\n",
    "        chain_pairs: Sequence[Tuple[RandomVariable, RandomVariable]] = (),\n",
    "        initial_chain_condition: Condition = (),\n",
    ") -> Sampler\n",
    "```\n",
    "\n",
    "`rvs` is a list of random variables to sample. They should all be from the source PGM.\n",
    "\n",
    "If `rvs` is a random variable object, then samples are yielded as integers representing state indexes from the random variable.\n",
    "\n",
    "If `rvs` is an array of random variables, then samples are yielded as `Instance` objects. Each instance is a list of integers co-indexed with the given random variables, and where each integer represents a state index from the corresponding random variable.\n",
    "\n",
    "If `rvs` is None, then all random variables from the source PGM will be used, in the order reported by the PGM.\n",
    "\n",
    "`condition` is a collection of zero or more conditioning indicators. Semantically, the indicators of the given condition are grouped by random variable. The condition is interpreted as the conjunction of the groups, and the disjunction of the states within each group. For example, given condition for the Student PGM,\n",
    "```\n",
    "    grade('1'), intelligent('Yes'), grade('3')\n",
    "```\n",
    "then the condition interpretation is: (grade = 1 or grade = 3) and intelligent = Yes.\n",
    "\n",
    "Note that `WMCProgram` and `MarginaslProgram` objects are created from a `PGMCircuit`, which may already have some condition compiled into the circuit. If both the circuit has a condition and the sampler has a condition, they are treated conjunctively, even if the same random variable is referenced in the conditions. For example, given\n",
    "```\n",
    "    circuit condition: grade('2')\n",
    "    sampler condition: grade('1'), intelligent('Yes'), grade('3')\n",
    "```\n",
    "then the condition interpretation is: grade = 2 and (grade = 1 or grade = 3) and intelligent = Yes. Note that in this example, the two conditions form a contradiction so all possible worlds have zero probability and no sampler could function normally.\n",
    "\n",
    "`rand` is an optional stream of random numbers, conforming to the `Random` protocol (package `ck.random_extras`). The default is the standard Python `random` package`.\n",
    "\n",
    "The parameters `chain_pairs` and `initial_chain_condition` provide a mechanism to construct complex Markov chains from any PGM.\n",
    "\n",
    "`chain_pairs` is a collection of pairs of random variables, each random variable\n",
    " must one that is actually being sampled. Given a pair (_from_rv_, _to_rv_) the state of _from_rv_ is used\n",
    " as a condition for _to_rv_ prior to generating the next sample.\n",
    " Caution is advised to ensure that such chains of conditions cannot contradict with conditions provided to the sampler or conditions compiled into the circuit. If a state is reached where there is a contradiction, then all possible worlds have zero probability and no sampler could function normally.\n",
    "\n",
    "`initial_chain_condition` are condition indicators (with the same format as `condition`)\n",
    " for the initialisation of the _to_rv_ random variables mentioned in `chain_pairs`.\n",
    " Caution is advised to ensure that given initial conditions do not contradict with  conditions provided to the sampler or conditions compiled into the circuit. If there is a contradiction, all possible worlds have zero probability and no sampler could function normally.\n",
    "\n",
    "Dependant samplers (Gibbs and Metropolis-Hastings) will have options specific to that style of sampling: `skip`, `burn_in` and `pr_restart`.\n",
    "\n",
    "`skip` is an integer ≥ 0 specifying how may samples to discard before a sample is provided. Values > 0 can be used to help de-correlate nearby samples.\n",
    "\n",
    "`burn_in` determines how many iterations to perform at the start, before providing the first sample. This is provided to deal with need to \"warm-up\" a Markov chain.\n",
    "\n",
    "`pr_restart`: the chance of re-initialising each time a sample is provided. If restarted then the sampler state is randomised and burn-in is performed again. This is provided to deal with the problem where a Markov chain gets stuck in a mode of high probability and fails to explore other important areas of the sample space.\n",
    "\n",
    "In general, creating a sampler can be customized by optional parameters similar to those above. Which options are available depends on the sampler implementation details.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
